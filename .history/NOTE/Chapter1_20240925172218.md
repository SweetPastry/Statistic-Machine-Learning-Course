@import "../style.less"


# 【统计学习】李航, 第一章笔记与习题解答. 示性函数, Markov 不等式, Chebyshev 不等式, Chernoff 界, Hoeffding 不等式, 泛化误差上界

## 示性函数 (indicative function)
> 示性函数的期望恰等于随机事件的概率, 即
> $$E\left( I_A \right) =P\left( A \right) .$$

首先回顾示性函数的定义:

$$
I_A\left( x \right) =\begin{cases}
	1,&		x\in A,\\
	0,&		x\notin A.\\
\end{cases}
$$

容易直接计算其期望,

$$
E\left( I_A \right) =P\left( A \right) \cdot 1+P\left( \bar{A} \right) \cdot 0=P\left( A \right) .
$$

## Markov 不等式
> 对于非负随机变量 $X\geqslant0$, 考虑随机事件: $X\geqslant a$, 其中 $a\geqslant0$, 那么有如下估计:
> $$P\left( X\geqslant a \right) \leqslant \frac{E\left( X \right)}{a}.$$

这个不等式的证明需要借助一些数形结合, 我们画出示性函数的图像:


<img src="./indicativeFunction.svg" class="centre" style="display: block; margin: 0 auto; width: 75%; height: auto;">
<!-- display: block;：将图片作为块级元素，便于应用 margin 属性。
margin: 0 auto;：通过左右自动边距，使图片居中。
width: 100%;：设置图片宽度为页面宽度的 100%。
height: auto;：保持图片的纵横比，不失真。 -->

于是我们有

$$
I_A\leqslant \frac{X}{a}.
$$

两边取期望

$$
E\left( I_A \right) \leqslant \frac{E\left( X \right)}{a}.
$$

然后利用示性函数的性质

$$
P\left( X\geqslant a \right) \leqslant \frac{E\left( X \right)}{a}.
$$

当然, 我们也可以用积分放缩的方法证明:

$$
\begin{align*}
E\left( X \right) &=\int_{\mathbb{R}}{XP\left( X \right) \mathrm{d}X=}\int_0^{+\infty}{XP\left( X \right) \mathrm{d}X}
\\\\
&\geqslant \int_a^{+\infty}{XP\left( X \right) \mathrm{d}X}\geqslant \int_a^{+\infty}{aP\left( X \right) \mathrm{d}X}
\\\\
&=aP\left( X\geqslant a \right) .
\end{align*}
$$

Markov 不等式很容易推导出其他估计, 例如代入 $\mathrm{e}^{\lambda X}$, 其中 $\lambda>0$, 有
> **(Chernoff bound)** 对于随机变量 $X$ 以及任意的 $\lambda\geqslant0$, 成立:
> $$E\left( \mathrm{e}^{\lambda X}\geqslant \mathrm{e}^{\lambda a} \right) \leqslant \frac{E\left( \mathrm{e}^{\lambda X} \right)}{\mathrm{e}^{\lambda a}}.$$

## Chebyshev 不等式
> 对于随机变量 $X\in \mathbb{R}$, 记 $\mu =E\left( X \right)$, 则存在以下估计
> $$P\left( \left| X-\mu \right|\geqslant a \right) \leqslant \frac{D\left( X \right)}{a^2}.$$

同样利用数形结合以及示性函数的性质, 有

<img src="./indicativeFunction2.svg" class="centre" style="display: block; margin: 0 auto; width: 85%; height: auto;">

$$
I_A\leqslant \frac{\left( X-\mu \right) ^2}{a^2}.
$$

两边同时取期望得到

$$
E\left( I_A \right) =P\left( A \right) \leqslant \frac{E\left[ \left( X-\mu \right) ^2 \right]}{a^2}=\frac{D\left( x \right)}{a^2}.
$$

## Hoeffding 不等式
先陈述一下 Hoeffding 引理：

> 对随机变量 $X$ 有：
> $$E\left( \mathrm{e}^{sX} \right) \leqslant \mathrm{e}^{\frac{s^2\left( b-a \right) ^2}{8}}.$$


Hoeffding 引理的证明可以参考[这篇文章](https://mp.weixin.qq.com/s/olxUqEp8m0v97lAfB3xF9g)的 Q2, 下面我们我们陈述 Hoeffding 不等式并证明:

> 对于随机变量 $X_i\in \left[ a_i,b_i \right]$, 记 $\bar{X}=\frac{1}{N}\sum\limits_{i=1}^N{X_i}$, $\mu =E\left( \bar{X} \right)$, 那么
> $$P\left( \bar{X}-\mu \geqslant t \right) \leqslant \exp \left( -\frac{2N^2t^2}{\sum\limits_{i=1}^N{\left( b_i-a_i \right) ^2}} \right),\\P\left( \mu-\bar{X} \geqslant t \right) \leqslant \exp \left( -\frac{2N^2t^2}{\sum\limits_{i=1}^N{\left( b_i-a_i \right) ^2}} \right) . $$

只证一种情况, 另一种情况同理可证. 设 $s\geqslant 0$, 那么 $\exp sX$ 就是 $\mathbb{R}$ 上的单调递增函数, 于是

$$
P\left( \bar{X}-\mu \geqslant t \right) =P\left[ \exp \left[ s\left( \bar{X}-\mu \right) \right] \geqslant \exp st \right] .
$$

利用 Chernoff 界, 得到

$$
P\left( \bar{X}-\mu \geqslant t \right) \leqslant \exp \left( -st \right) E\left[ \exp \left[ s\left( \bar{X}-\mu \right) \right] \right] .
$$

然后将 $\bar{X}$ 写开来, 并记得 $X_i$ 相互独立, 

$$
\begin{align*}
P\left( \bar{X}-\mu \geqslant t \right) &=\exp \left( -st \right) E\left[ \prod_{i=1}^N{\exp \frac{s}{N}\left( X_i-E\left( X_i \right) \right)} \right] 
\\
&=\exp \left( -st \right) \prod_{i=1}^N{E\left[ \exp \frac{s}{N}\left( X_i-E\left( X_i \right) \right) \right]}
\end{align*}
$$

利用 Hoeffding 引理, 得到

$$
P\left( \bar{X}-\mu \geqslant t \right) \leqslant \exp \left( -st \right) \prod_{i=1}^N{\exp \frac{s^2\left( b_i-a_i \right) ^2}{8N^2}}=\exp \left( -st \right) \exp \frac{s^2\sum\limits_{i=1}^N{\left( b_i-a_i \right) ^2}}{8N^2}.
$$

整理得到

$$
P\left( \bar{X}-\mu \geqslant t \right) =\exp \left( -st+\frac{s^2\sum\limits_{i=1}^N{\left( b_i-a_i \right) ^2}}{8N^2} \right). 
$$

注意到 $s>0$ 是任给的, 我们还可以在 $s$ 上做优化, 记

$$
F\left( s \right) =-st+\frac{s^2\sum\limits_{i=1}^N{\left( b_i-a_i \right) ^2}}{8N^2}.
$$

求导

$$
F^{\prime}\left( s \right) =-t+\frac{s\sum\limits_{i=1}^N{\left( b_i-a_i \right) ^2}}{4N^2}.
$$

得到

$$
s_0=\frac{4N^2t}{\sum\limits_{i=1}^N{\left( b_i-a_i \right) ^2}}.
$$

所以

$$
F\left( s \right) \geqslant F\left( s_0 \right) =-\frac{2N^2t}{\sum\limits_{i=1}^N{\left( b_i-a_i \right) ^2}}.
$$

这就证明了 Hoeffding 不等式

$$
P\left( \bar{X}-\mu \geqslant t \right) \leqslant \exp \left( -\frac{2N^2t^2}{\sum\limits_{i=1}^N{\left( b_i-a_i \right) ^2}} \right).
$$

## 泛化误差上界
> 对于**二分类问题**, 如果假设空间内只有有限个函数 $\mathcal{F} =\left\{ f_1,f_2,\cdots ,f_d \right\}$, 且损失函数取值于 $[0,1]$, 对于任意的 $f\in\mathcal{F}$, 设 $R(f)$ 为泛化误差, $\hat{R}\left( f \right)$ 为训练误差, 则至少有 $1-\delta$, $0<\delta<1$ 的概率, 成立以下估计
> $$R\left( f \right) \leqslant \hat{R}\left( f \right) +\varepsilon \left( d,N,\delta \right),$$
> 其中
> $$\varepsilon \left( d,N,\delta \right) =\sqrt{\frac{1}{2N}\left( \log d+\log \frac{1}{\delta} \right)}.$$

即证明

$$
P\left[ \forall f\in \mathcal{F} :\ R\left( f \right) -\hat{R}\left( f \right) \leqslant \sqrt{\frac{1}{2N}\left( \log d+\log \frac{1}{\delta} \right)} \right] \geqslant 1-\delta .
$$

即证明

$$
P\left[ \exists f\in \mathcal{F} :\ R\left( f \right) -\hat{R}\left( f \right) > \sqrt{\frac{1}{2N}\left( \log d+\log \frac{1}{\delta} \right)} \right] \leqslant \delta .
$$

此处遍历集合里的每一个函数, 寻找符合条件的 $f$, 所以左侧式子可以写作求和的形式:

$$
P\left[ \exists f\in \mathcal{F} : R\left( f \right) -\hat{R}\left( f \right) >\sqrt{\frac{1}{2N}\left( \log d+\log \frac{1}{\delta} \right)} \right] 
\\
=\bigcup_{f\in \mathcal{F}}{P\left[ R\left( f \right) -\hat{R}\left( f \right) >\sqrt{\frac{1}{2N}\left( \log d+\log \frac{1}{\delta} \right)} \right]}.
$$

利用 Hoeffding 不等式得到加强的命题

$$
\bigcup_{f\in \mathcal{F}}{\exp \left( -\frac{2d^2}{\sum\limits_{i=1}^n{\left( b_i-a_i \right) ^2}}\frac{1}{2d}\left( \log d+\log \frac{1}{\delta} \right) \right)}
\\
=d\cdot \exp \left( -\frac{2d^2}{\sum\limits_{i=1}^n{\left( b_i-a_i \right) ^2}}\frac{1}{2d}\left( \log d+\log \frac{1}{\delta} \right) \right) \leqslant \delta.
$$

利用误差的取值范围

$$
d\cdot\exp \left( - \log d-\log \frac{1}{\delta}  \right) \leqslant \delta .
$$

即

$$
\delta \leqslant\delta.
$$

得证. 此段证明, 在运用 Hoeffding 引理处, 认为泛化误差 $\hat{R}$ 为训练误差 $R$ 的期望, 我个人认为这种观点不太正确, 因为模型在训练集上训练, 训练误差是被降得很小得, 而泛化误差是考虑全部的数据, 误差是相对大的. 此处, 应该把测试误差 $R_{\mathrm{test}}$ 的期望当作是泛化误差的估计, 即多进行一步放缩 (不影响论述):

$$
R\left( f \right) -\hat{R}\left( f \right) \geqslant R\left( f \right) -R_{\mathrm{test}}\left( f \right) .
$$

## 习题解答

> **1.1** 说明伯努利模型的极大似然估计以及贝叶斯估计中的统计学习方法三要素. 伯努利模型是定义在取值为 0 与 1 的随机变量上的概率分布. 假设观测到伯努利模型n次独立的数据生成结果, 其中 $k$ 次的结果为 1, 这时可以用极大似然估计或贝叶斯估计来估计结果为 1 的概率.


> **1.2** 通过经验风险最小化推导极大似然估计. 证明模型是条件概率分布, 当损失函数是对数损失函数时, 经验风险最小化等价于极大似然估计.

## 参考